{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "Lab_two_CART_and_RF_solutions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJO6wLqtku-o"
      },
      "source": [
        "<center>\n",
        "    <h3>University of Toronto</h3>\n",
        "    <h3>Department of Mechanical and Industrial Engineering</h3>\n",
        "    <h3>MIE368 Analytics in Action </h3>\n",
        "    <h3>(Fall 2020)</h3>\n",
        "    <hr>\n",
        "    <h1>Lab 2: Classification and Regression Trees (CART) and Random Forest</h1>\n",
        "    <h3>September 30, 2020</h3>\n",
        "</center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BgIYDa5lku-p"
      },
      "source": [
        "# Introduction\n",
        "In this lab we investigate the use of classification and regression trees (CART) and random forests. Unlike linear and logistic regression, these methods do not make any assumptions about the target variable being linearly dependent on the independent feature variables. Instead, they are data-driven and use a number of logical rules to classify observations and make associated predictions. CART and random forests can be used to predict both continuous and discrete (categorical) targets.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPG_vr_iM1gS"
      },
      "source": [
        "## Background and Methods\n",
        "In this section we provide a high-level description of the methods studied within this lab, namely CART and random forests. These methods are forms of decision tree learning where sample observation characteristics are mapped to conclusions about the sample observation’s target value (i.e., the prediction). The main difference between the two methods is that CART uses a single decision tree while random forests use multiple trees, as discussed in subsequent sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "735d7weSlayD"
      },
      "source": [
        "## Classification and Regression Trees (CART) Information\n",
        "These models consist of a single decision tree that looks to capture non-linearities between the input features and the output target. A major advantage that CART models have over other classification models such as logistic regression, is their interpretability. While logistic regression is useful in describing the likelihood of an event to be predicted, a CART model can procedurally show exactly what each feature needs to be in order to yield a given event.\n",
        "\n",
        "If we recall from lecture, CART was presented in the context of the American Supreme Court, where we looked to predict whether the Supreme Court judges (Justices) would affirm (uphold) or reverse (overturn) lower court decisions. Model predictions were made based on six feature variables with associated binary (yes/no) responses. These variables include responses to questions such as: i) Is the lower court decision liberal? ii) Is the case from District _A_?. In this particular application, the interpretability of a specific prediction is highly valued.\n",
        "\n",
        "Figure 1 illustrates a CART for a colour prediction problem with two feature variables and two output classes (i.e., red or gray). To build a CART model we _split_ on the selected feature variables (in some particular order), producing child nodes from each parent node. Each split is based on a single independent feature variable. For the model illustrated in Figure 1, our first split uses the question \"is $X < 60$?\", which produces a binary yes/no response. If the response is _yes_ then we classify the observation as red immediately, however, if the response is _no_, deeper nodes within the tree must be explored. \n",
        "\n",
        "<img src=\"https://docs.google.com/uc?export=view&id=1uWGSkB2AlAx0DcyS_9DgO-YJeQNsPZKu\" \n",
        "alt=\"\"/>\n",
        "\n",
        "Figure 1: Classification and regression tree (CART) with two feature variables.\n",
        "\n",
        "A prediction (classification) of the observation is made whenever a leaf node (i.e., a node with no children) is reached within the decision tree. At such leaves the percentage of observations in a given group (e.g., red or gray) is calculated and a threshold is applied to make a prediction. The splits within a CART are selected to produce the most _pure_ children (i.e., the cleanest separation of the classes). In this example there are only two classes, however, CART can be used for multi-class problems as well as continuous problems.\n",
        "\n",
        "There are a number of choices to make when designing and training a specific CART model, including:\n",
        "\n",
        "- Which feature variable should we split on? When? Some relevant metrics for answering these questions are Gini and Entropy measures.\n",
        "- How many splits are generated within our CART? For example, you could try constraining the number of splits generated using lower/upper bounds.\n",
        "\n",
        "Such parameter selection for the design of CART models is crucial to the performance of the model. In general, we try to select parameter values that produce good results. Though it may be tempting, choosing the parameters that yield the highest prediction accuracy is not necessarily the way to go due to overfitting. As discussed in previous labs, techniques such as K-Fold Cross Validation can ensure our parameters will perform best on various input observation sets, thus avoiding this issue.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lf_sxK0tq6m"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Answer the following review questions related to CART:\n",
        "1. Would a statistically insignificant variable be useful to split on in a CART model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI1P3Hb8ku-s"
      },
      "source": [
        "  ___\n",
        " __Question 1 Answer__:\n",
        "\n",
        "In general, we want to include variables that most drastically impact our target variable, namely, statistically significant variables. However, there may be cases were a statistically insignificant variable can be useful.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IrmC2hlku-t"
      },
      "source": [
        "2. Should we always select the CART design parameters that maximize accuracy on the test set?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dsKEH-SNku-v"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "\n",
        "If you do, then the test set score becomes a biased measure of your model quality. It is more appropriate to use cross-validation, as we technically never \"see\" the test set when training the model.\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxn2Pp8oku-w"
      },
      "source": [
        "3. True/False: CART models can only be used for problems with two prediction classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbKMbB1-ku-w"
      },
      "source": [
        "___\n",
        "__Question 3 Answer__:\n",
        "False. CART can be used to predict a categorical target variable (ie. predict blue, red or green). It can also be used to predict a continuous target variable.\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MNMelFwku-x"
      },
      "source": [
        "## Random Forests Information\n",
        "\n",
        "This approach was designed primarily as a way to boost the performance of CART. Random forests are a form of ensemble method that combines predictions from multiple models to attain a better overall performance than each of the individual underlying models. Specifically, random forests combine a large number of CART trees, each of which ‘vote’ on the outcome, to deduce a final prediction. Although there are a large number of voting rules that could be used, a simple and common one for classification is a _majority rule_, which states that if most of the trees in a forest give a certain prediction, then the forest gives that same prediction. A similarly simple rule for regression ensembles is an average rule.\n",
        "\n",
        "Random forests are formed by running CART on a subset of the observations (from the total training set) and a subset of feature variables (from the total feature variable set). Note, it is common practice to use a subset of observations, but it is not strictly required. The process of creating a subset of observations used in random forest (and other ensemble methods) is termed *bootstrap aggregating*, or *bagging*, (the term bagging is derived as a short form of **b**ootstrap **agg**regat**ing**). \n",
        "\n",
        "Within the bootstrap aggregating (bagging) approach, we create multiple *bootstrapped* samples of the dataset. Each bootstrapped sample has size $m$ and does not have to be the same size of the full dataset, $n$. When creating each bootstrapped sample, we sample with replacement from the full dataset, meaning we could have duplicate rows from the original dataset in our bootstrapped sample. For example, two valid bootstrapped samples of the dataset {$1,2,3,4,5$} could be {$1,3,4$} and {$2,5,2$}, as they contain only elements from the original data set, and both samples are the same size ($m=3$).\n",
        "\n",
        "To summarize, *Bootstrapping* is a sampling technique and *Bagging* is a machine learning ensemble model that is built using bootstrapped samples.\n",
        "\n",
        "As covered in CART, there are a number of parameter design decisions to make for a specific random forest model (independent of the underlying CART design):\n",
        "\n",
        " - The number of CART trees to build (typically set to the order of $10^2$)\n",
        " - More trees can result in longer computation times, but typically stronger performance (i.e., tradeoff in construction time and prediction performance)\n",
        " \n",
        "These parameter choices are in addition to those selected for CART design (e.g., size of each individual trees). Due to their ensemble nature, random forests are less sensitive to model parameters, however, how they arrive at their predictions is effectively impossible to inteprete (making it a _black box_). As a black box, a random forest is likely not suitable for the Supreme Court example covered in lecture. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qqiaUCZueRa"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Answer the following questions related to random forest:\n",
        "1. Could you combine a CART tree and a logistic regression as an ensemble method? Why/why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tR4BHb7pku-y"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "\n",
        "Yes, both are viable base models that can be included in an ensemble method. We would use the outcomes from both models to \"vote\" for an aggregate prediction. \n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYvcAKqYku-z"
      },
      "source": [
        "2. What would a potential bootstrapped sample of the dataset {1,2,3,4,5,6} be?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMXpo_aRku-0"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "\n",
        "{1, 1, 3, 2, 4, 5}\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ynciyPANku-2"
      },
      "source": [
        "3. True/False: The predictions of a random forest are more easily interpreted than those of a single CART tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fp7vpjJfku-3"
      },
      "source": [
        "___\n",
        "__Question 3 Answer__:\n",
        "False. Since we use many individual CART trees within a random forest, there is no one particular decision tree in which we can intuitively follow through each split until we end up with a prediction. Random forests are thus considered more of a *black box* type model.\n",
        "___\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtZtfRO0ku-4"
      },
      "source": [
        "# Application\n",
        "In this lab, we investigate vandalism in Wikipedia (en.wikipedia.org). Wikipedia is the world’s largest free online encyclopedia, containing in the neighbourhood of 5.8 million articles with roughly 156,000 edits per day. Wikipedia allows anyone to contribute/edit entries, which promotes rapid content creation and community-based error checking. An unfortunate side effect of this approach is the presence of vandalism. Specifically, we refer to pages that have had information removed, incorrect information added, or the presence of inappropriate content. Due to the volume of entries being changed on a daily basis, it is incredibly difficult to manually (i.e., human checking) ensure the accuracy of pages and remove any instances of vandalism.\n",
        "\n",
        "In this lab, we will look at a dataset that summarizes the revision history for the [“Language” entry on Wikipedia](https://en.wikipedia.org/wiki/Language). We will conduct some exploratory data analysis (EDA) and look into predicting whether a particular revision was an instance of vandalism or not. For this application, an accurately performing model can be very useful - the free and accurate flow of world information depends on it! Please answer the questions wherever a blank is provided, and discuss answers with your peers.\n",
        "\n",
        "The following sections detail the main steps associated with this lab. First, we will start by understanding decision trees (CART) a little better through the use of a written example. Next, we use `sklearn` to explore the data and build CART trees and random forests for the full Wikipedia dataset. Let’s get started! As usual we will load the necessary packages and load the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7Lp6oiaku-5",
        "outputId": "c9e05c5a-0eab-4990-b19e-83455a8ccf10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "# Import packages\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.tree import export_graphviz\n",
        "from IPython.display import SVG\n",
        "from graphviz import Source\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('https://docs.google.com/uc?export=download&id=1zIXF6ReaoqdglnMsQf5u6zQdfEvu8paT') \n",
        "df.head() # prints the first 5 rows of the dataframe "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Vandal</th>\n",
              "      <th>Minor</th>\n",
              "      <th>LoggedIn</th>\n",
              "      <th>HTTP</th>\n",
              "      <th>NumWordsAdded</th>\n",
              "      <th>NumWordsRemoved</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>96</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>94</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Vandal Minor LoggedIn HTTP NumWordsAdded NumWordsRemoved\n",
              "0      0     1        1    1            96               0\n",
              "1      0     1        1    0             3               1\n",
              "2      0     0        1    0             0               4\n",
              "3      0     1        0    0            10              92\n",
              "4      0     1        1    1            94              10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSDeVuBpku_A"
      },
      "source": [
        "The table below contains the data dictionary.\n",
        "\n",
        "|Feature          |Definition                                             |\n",
        "|:---------------:|:------------------------------------------------------|\n",
        "|Vandal           |1 if the edit was vandalism, 0 if not                  |\n",
        "|Minor            |1 if the edit was marked as a minor edit, 0 if not     |    \n",
        "|LoggedIn         |1 if the user made edit from Wiki account, 0 if not    |\n",
        "|HTTP             |1 if edit contained web address, 0 if not              | \n",
        "|NumWordsAdded    |Number of unique words added                           |\n",
        "|NumWordsRemoved  |Number of unique words removed                         |\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRQ2bJhmvZmV"
      },
      "source": [
        "## Decision Trees by Hand (Pencil and Paper)\n",
        "\n",
        "You are given a small sample of the total Wikipedia vandalism data as illustrated\n",
        "below. The first two rows in the sample data contains two entry edits that were not vandalism, and last two edits  were. Given this data, design and illustrate two different binary decision trees (CART trees) that meet the following criteria:\n",
        "\n",
        "1. First CART tree: Classifies all data points with 100% accuracy.\n",
        "2. Second CART tree: Uses a maximum of two splits, and classifies the data with $\\ge$ 75% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UP9JV4MGku_B",
        "outputId": "672eab65-dcd7-4953-df3e-adb75e221b14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "print(df.loc[list([0,1,2843,2844])])\n",
        "\n",
        "# Write your code here.\n",
        "\n",
        "# -------------------\n",
        "\n",
        "# Tree 1:\n",
        "#   Minor < 0.5?:\n",
        "#     Yes => Vandal = 1\n",
        "#     No => NumWordsAdded > 2?:\n",
        "#       Yes => Vandal = 0\n",
        "#       No => Vandal = 1\n",
        "#\n",
        "# This tree works for both.\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Vandal Minor LoggedIn HTTP NumWordsAdded NumWordsRemoved\n",
            "0         0     1        1    1            96               0\n",
            "1         0     1        1    0             3               1\n",
            "2843      1     1        1    0             1              12\n",
            "2844      1     0        1    0            13               0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRZ5EcpcxbdU"
      },
      "source": [
        "## Exploratory data analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBEZWBlIku_F"
      },
      "source": [
        "### Exercise \n",
        "\n",
        "Prior to using CART and random forests to make predictions, we start with EDA to get a better feel for the Wikipedia dataset we are using.\n",
        "1. Are there any non-numerical data values?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TALkVINFku_H",
        "outputId": "32ad9a2e-c0ac-487a-d1be-5e33146fdfcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "# df_digit_indicator is calculated below to get you started. \n",
        "df_digit_indicator = df.applymap(lambda x: x.isdigit())  \n",
        "\n",
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "number_non_digits = (df_digit_indicator==0).sum()\n",
        "\n",
        "print(f'There are non-numerical values as follows \\n{number_non_digits}')\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are non-numerical values as follows \n",
            "Vandal             2\n",
            "Minor              1\n",
            "LoggedIn           2\n",
            "HTTP               1\n",
            "NumWordsAdded      2\n",
            "NumWordsRemoved    1\n",
            "dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJJQ0PeOviUl"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "\n",
        "The number of non-numeric values for each column is: Vandal (2), Minor (1), LoggedIn (2), HTTP (1), NumWordsAdded (2) and NumWordsRemoved (1).\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTaBzbxHku_J"
      },
      "source": [
        "2. Are they properly stored as `NaN`, and if not, what are they stored as?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAJgO2X3ku_J",
        "outputId": "453a6849-2d0e-40eb-b188-775803f6dc3f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "for col in df.columns:\n",
        "  print(df[col][df_digit_indicator[col] == False].value_counts())\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ERROR    2\n",
            "Name: Vandal, dtype: int64\n",
            "ERROR    1\n",
            "Name: Minor, dtype: int64\n",
            "ERROR    2\n",
            "Name: LoggedIn, dtype: int64\n",
            "ERROR    1\n",
            "Name: HTTP, dtype: int64\n",
            "ERROR    2\n",
            "Name: NumWordsAdded, dtype: int64\n",
            "ERROR    1\n",
            "Name: NumWordsRemoved, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78UOls23v_ao"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "\n",
        "The non-numeric values are stored as \"ERROR\". We need to replace these with proper NaNs.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tU1FUzaFku_L"
      },
      "source": [
        "Now that we have identified some issues with the data, we should clean it and ensure all the entries are integer.\n",
        "\n",
        "3. Remove any invalid data points from `df`. Use this new `df` for the remainder of this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i7GG8A9ku_M"
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "df = df.replace('ERROR', np.nan)\n",
        "df = df.dropna()\n",
        "\n",
        "# -------------------\n",
        "\n",
        "# Once the rows are deleted (or even before) it's important to ensure\n",
        "# that all elements in this df are numeric. The code below will change\n",
        "# strings to numeric values. \n",
        "\n",
        "df = df.apply(pd.to_numeric, errors='coerce')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRQResYOku_P"
      },
      "source": [
        "It will be easier to continue the EDA now that we have clean data in `df`.\n",
        "\n",
        "4. How many edits are considered? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad3eVJ2Aku_P",
        "outputId": "f77bf4d5-0f73-4e98-b5ba-510787155283",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "number_of_edits = len(df)\n",
        "print(f'There are {number_of_edits} edits considered.')\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 3867 edits considered.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6i5VUOHwY7u"
      },
      "source": [
        "___\n",
        "__Question 4 Answer__:\n",
        "\n",
        "There are 3867 edits considered.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "54efttQVku_U"
      },
      "source": [
        "5. What percentage of the edits were deemed to be vandalism?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pd13DCubku_U",
        "outputId": "ad0e4209-8b13-47d8-8156-c90a1e45d1b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "percent_vandal = df['Vandal'].mean()*100\n",
        "print(f'{percent_vandal:.2f}% of the edits were vandalism.')\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "46.75% of the edits were vandalism.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv2dBgM_wdEh"
      },
      "source": [
        "___\n",
        "__Question 5 Answer__:\n",
        "\n",
        "46.75% of the edits were vandalism.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hW9xrQ4ku_W"
      },
      "source": [
        "6. Was the edit with the most added words a case of vandalism?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK68Q5jjku_W",
        "outputId": "7efa733b-c681-46a7-c54c-07341c60920b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "most_words_added_vandal_index = df.NumWordsAdded.loc[df.Vandal==1].idxmax()\n",
        "most_words_added_by_vandal = df.NumWordsAdded.loc[most_words_added_vandal_index]\n",
        "print(f'Of all vandal edits, number {most_words_added_vandal_index} added the most words ({most_words_added_by_vandal}).')\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Of all vandal edits, number 2829 added the most words (138).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ncI8uk9UwvpM"
      },
      "source": [
        "___\n",
        "__Question 6 Answer__:\n",
        "\n",
        "Of all vandal edits, number 2829 added the most words (138).\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNhc-xrmku_Z"
      },
      "source": [
        "7. Based on a cursory review of the dataset, which two feature variables (e.g., Minor, LoggedIn, HTTP, NumWordsAdded, and NumWordsRemoved) do you believe to be the most significant in predicting vandalism? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEyiV42Uku_Z"
      },
      "source": [
        "___\n",
        "__Question 7 Answer__:\n",
        "\n",
        "This answer is based on intuition and domain knowledge. We can suspect that the most important variables may be `LoggedIn` and `HTTP`. This is because vandals would most likely not want to be known/tracked. When we create the model, we will see which features really were the most important.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zqd6JstLku_a"
      },
      "source": [
        "## Splitting the Data\n",
        "Randomly split data clean into a training set and test set, named data train and data test, respectively. We will place 70% of the data into the training set and the remainder in the test set. We will do this using the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function from `sklearn.model_selection`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DoYnecqku_c"
      },
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.drop('Vandal',1), df['Vandal'], test_size=0.30, random_state=5)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiTTmBmjku_e"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "1. How many points are in the training set?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEVQsiFVku_e",
        "outputId": "7f1ae963-a15c-4e6b-bdae-d945b0d28d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "len(y_train)\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2706"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xatNlgg0x3kA"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "\n",
        "There are 2706 points in the training set.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhFvTq3Oku_g"
      },
      "source": [
        "2. How many confirmed vandalisms are in y_train?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk0Pj2WAku_g",
        "outputId": "e7791c06-9dbf-455c-8ca1-3ce7972a6cee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "sum(y_train)\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1257"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SojRxhuox8kw"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "\n",
        "There are 1257 instances of vandalism in the training set.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-VaQhVoku_h"
      },
      "source": [
        "# Using CART and RF with sklearn\n",
        "\n",
        "In the next section we will go over how the use the CART and RF classifiers in `sklearn`. The purpose of both of these methods is to classify target variables (e.g., Wikipedia edit is or is not vandalized), hence, these methods are more similar to logistic regression than they are to linear regression. Note, that random forest regression is also available in `sklearn`, which should be used instead of the classifiers if you're looking for a model to predict continuous values between positive and negative infinity (e.g., number of edits).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q62UtTfLNTGF"
      },
      "source": [
        "## CART Model\n",
        "\n",
        "Use the [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) function within `sklearn.tree`  to fit a CART model to the training set. There are several parameters that you can tune to prevent over fitting and to get better model accuracy. Recall that cross validation should be used to pick the best parameters for the model, but for simplicity we will neglect that step in this lab. One parameter you can set is `max_depth`, which controls the maximum number of levels in your trained model. In the example below we set the `max_depth` to three and visualize the resulting tree.  Figure 2 illustrates what a possible CART tree could look like for this application. Based on your produced tree, answer the following questions:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1axqvdVku_i",
        "outputId": "b40d9221-34d4-4991-e870-319c4d990324",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 635
        }
      },
      "source": [
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.tree import export_graphviz\n",
        "# from IPython.display import SVG\n",
        "# from graphviz import Source\n",
        "\n",
        "# Train the CART model\n",
        "cart_model = DecisionTreeClassifier(random_state=3,max_depth=3)\n",
        "cart_model.fit(X_train, y_train)\n",
        "train_score = cart_model.score(X_train, y_train)\n",
        "test_score = cart_model.score(X_test, y_test)\n",
        "\n",
        "# Print out summary of model performance \n",
        "print('The score of this model over training data is {:.3f} and {:.3f} over the testing data'.format(train_score, test_score))\n",
        "\n",
        "# Visualize the decision tree\n",
        "cart_graph = Source(export_graphviz(cart_model,\n",
        "                   feature_names = df.columns[1:],\n",
        "                   rounded = True, proportion = False, \n",
        "                  filled = True,\n",
        "                  class_names=['0','1']))\n",
        "SVG(cart_graph.pipe(format='svg'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The score of this model over training data is 0.730 and 0.717 over the testing data\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"433pt\" viewBox=\"0.00 0.00 1134.00 433.00\" width=\"1134pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-429 1130,-429 1130,4 -4,4\" stroke=\"transparent\"/>\n<!-- 0 -->\n<g class=\"node\" id=\"node1\">\n<title>0</title>\n<path d=\"M586.5,-425C586.5,-425 461.5,-425 461.5,-425 455.5,-425 449.5,-419 449.5,-413 449.5,-413 449.5,-354 449.5,-354 449.5,-348 455.5,-342 461.5,-342 461.5,-342 586.5,-342 586.5,-342 592.5,-342 598.5,-348 598.5,-354 598.5,-354 598.5,-413 598.5,-413 598.5,-419 592.5,-425 586.5,-425\" fill=\"#fceee5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-409.8\">LoggedIn &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-394.8\">gini = 0.497</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-379.8\">samples = 2706</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-364.8\">value = [1449, 1257]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"524\" y=\"-349.8\">class = 0</text>\n</g>\n<!-- 1 -->\n<g class=\"node\" id=\"node2\">\n<title>1</title>\n<path d=\"M497,-306C497,-306 345,-306 345,-306 339,-306 333,-300 333,-294 333,-294 333,-235 333,-235 333,-229 339,-223 345,-223 345,-223 497,-223 497,-223 503,-223 509,-229 509,-235 509,-235 509,-294 509,-294 509,-300 503,-306 497,-306\" fill=\"#76bbed\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-290.8\">NumWordsAdded &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-275.8\">gini = 0.36</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-260.8\">samples = 902</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-245.8\">value = [212, 690]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-230.8\">class = 1</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g class=\"edge\" id=\"edge1\">\n<title>0-&gt;1</title>\n<path d=\"M487.9756,-341.8796C480.1802,-332.8733 471.8633,-323.2644 463.8356,-313.9897\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"466.3691,-311.5686 457.1782,-306.2981 461.0763,-316.1498 466.3691,-311.5686\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"455.381\" y=\"-327.5334\">True</text>\n</g>\n<!-- 8 -->\n<g class=\"node\" id=\"node9\">\n<title>8</title>\n<path d=\"M750,-306C750,-306 598,-306 598,-306 592,-306 586,-300 586,-294 586,-294 586,-235 586,-235 586,-229 592,-223 598,-223 598,-223 750,-223 750,-223 756,-223 762,-229 762,-235 762,-235 762,-294 762,-294 762,-300 756,-306 750,-306\" fill=\"#f1bb94\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-290.8\">NumWordsAdded &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-275.8\">gini = 0.431</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-260.8\">samples = 1804</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-245.8\">value = [1237, 567]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-230.8\">class = 0</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g class=\"edge\" id=\"edge8\">\n<title>0-&gt;8</title>\n<path d=\"M576.4627,-341.8796C588.4521,-332.368 601.2887,-322.1843 613.5816,-312.432\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"615.9081,-315.054 621.5669,-306.0969 611.5575,-309.5701 615.9081,-315.054\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"618.7048\" y=\"-327.2326\">False</text>\n</g>\n<!-- 2 -->\n<g class=\"node\" id=\"node3\">\n<title>2</title>\n<path d=\"M286.5,-187C286.5,-187 113.5,-187 113.5,-187 107.5,-187 101.5,-181 101.5,-175 101.5,-175 101.5,-116 101.5,-116 101.5,-110 107.5,-104 113.5,-104 113.5,-104 286.5,-104 286.5,-104 292.5,-104 298.5,-110 298.5,-116 298.5,-116 298.5,-175 298.5,-175 298.5,-181 292.5,-187 286.5,-187\" fill=\"#fcefe6\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-171.8\">NumWordsRemoved &lt;= 2.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-156.8\">gini = 0.498</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-141.8\">samples = 300</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-126.8\">value = [160, 140]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-111.8\">class = 0</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g class=\"edge\" id=\"edge2\">\n<title>1-&gt;2</title>\n<path d=\"M343.7049,-222.8796C325.1152,-212.8697 305.1433,-202.1156 286.1773,-191.9031\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"287.7155,-188.7563 277.2514,-187.0969 284.3968,-194.9196 287.7155,-188.7563\" stroke=\"#000000\"/>\n</g>\n<!-- 5 -->\n<g class=\"node\" id=\"node6\">\n<title>5</title>\n<path d=\"M507.5,-187C507.5,-187 334.5,-187 334.5,-187 328.5,-187 322.5,-181 322.5,-175 322.5,-175 322.5,-116 322.5,-116 322.5,-110 328.5,-104 334.5,-104 334.5,-104 507.5,-104 507.5,-104 513.5,-104 519.5,-110 519.5,-116 519.5,-116 519.5,-175 519.5,-175 519.5,-181 513.5,-187 507.5,-187\" fill=\"#4ca6e7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-171.8\">NumWordsRemoved &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-156.8\">gini = 0.158</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-141.8\">samples = 602</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-126.8\">value = [52, 550]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421\" y=\"-111.8\">class = 1</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g class=\"edge\" id=\"edge5\">\n<title>1-&gt;5</title>\n<path d=\"M421,-222.8796C421,-214.6838 421,-205.9891 421,-197.5013\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"424.5001,-197.298 421,-187.2981 417.5001,-197.2981 424.5001,-197.298\" stroke=\"#000000\"/>\n</g>\n<!-- 3 -->\n<g class=\"node\" id=\"node4\">\n<title>3</title>\n<path d=\"M112,-68C112,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 112,0 112,0 118,0 124,-6 124,-12 124,-12 124,-56 124,-56 124,-62 118,-68 112,-68\" fill=\"#f6d5bd\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-52.8\">gini = 0.48</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-37.8\">samples = 243</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-22.8\">value = [146, 97]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"62\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g class=\"edge\" id=\"edge3\">\n<title>2-&gt;3</title>\n<path d=\"M148.6139,-103.9815C136.7839,-94.4232 124.2136,-84.2668 112.4249,-74.7419\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"114.3851,-71.826 104.4071,-68.2637 109.9858,-77.2708 114.3851,-71.826\" stroke=\"#000000\"/>\n</g>\n<!-- 4 -->\n<g class=\"node\" id=\"node5\">\n<title>4</title>\n<path d=\"M246,-68C246,-68 154,-68 154,-68 148,-68 142,-62 142,-56 142,-56 142,-12 142,-12 142,-6 148,0 154,0 154,0 246,0 246,0 252,0 258,-6 258,-12 258,-12 258,-56 258,-56 258,-62 252,-68 246,-68\" fill=\"#79bded\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-52.8\">gini = 0.371</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-37.8\">samples = 57</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-22.8\">value = [14, 43]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"200\" y=\"-7.8\">class = 1</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g class=\"edge\" id=\"edge4\">\n<title>2-&gt;4</title>\n<path d=\"M200,-103.9815C200,-95.618 200,-86.7965 200,-78.3409\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"203.5001,-78.2636 200,-68.2637 196.5001,-78.2637 203.5001,-78.2636\" stroke=\"#000000\"/>\n</g>\n<!-- 6 -->\n<g class=\"node\" id=\"node7\">\n<title>6</title>\n<path d=\"M388,-68C388,-68 288,-68 288,-68 282,-68 276,-62 276,-56 276,-56 276,-12 276,-12 276,-6 282,0 288,0 288,0 388,0 388,0 394,0 400,-6 400,-12 400,-12 400,-56 400,-56 400,-62 394,-68 388,-68\" fill=\"#46a3e7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-52.8\">gini = 0.113</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-37.8\">samples = 401</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-22.8\">value = [24, 377]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"338\" y=\"-7.8\">class = 1</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g class=\"edge\" id=\"edge6\">\n<title>5-&gt;6</title>\n<path d=\"M390.0939,-103.9815C383.3892,-94.9747 376.2892,-85.4367 369.5597,-76.3965\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"372.2845,-74.1953 363.5057,-68.2637 366.6694,-78.3752 372.2845,-74.1953\" stroke=\"#000000\"/>\n</g>\n<!-- 7 -->\n<g class=\"node\" id=\"node8\">\n<title>7</title>\n<path d=\"M530,-68C530,-68 430,-68 430,-68 424,-68 418,-62 418,-56 418,-56 418,-12 418,-12 418,-6 424,0 430,0 430,0 530,0 530,0 536,0 542,-6 542,-12 542,-12 542,-56 542,-56 542,-62 536,-68 530,-68\" fill=\"#59ade9\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-52.8\">gini = 0.24</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-37.8\">samples = 201</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-22.8\">value = [28, 173]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"480\" y=\"-7.8\">class = 1</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g class=\"edge\" id=\"edge7\">\n<title>5-&gt;7</title>\n<path d=\"M442.9694,-103.9815C447.5895,-95.2504 452.4736,-86.0202 457.126,-77.2281\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"460.2859,-78.7395 461.8694,-68.2637 454.0987,-75.4655 460.2859,-78.7395\" stroke=\"#000000\"/>\n</g>\n<!-- 9 -->\n<g class=\"node\" id=\"node10\">\n<title>9</title>\n<path d=\"M728,-187C728,-187 620,-187 620,-187 614,-187 608,-181 608,-175 608,-175 608,-116 608,-116 608,-110 614,-104 620,-104 620,-104 728,-104 728,-104 734,-104 740,-110 740,-116 740,-116 740,-175 740,-175 740,-181 734,-187 728,-187\" fill=\"#eca470\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-171.8\">Minor &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-156.8\">gini = 0.34</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-141.8\">samples = 784</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-126.8\">value = [614, 170]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"674\" y=\"-111.8\">class = 0</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g class=\"edge\" id=\"edge9\">\n<title>8-&gt;9</title>\n<path d=\"M674,-222.8796C674,-214.6838 674,-205.9891 674,-197.5013\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"677.5001,-197.298 674,-187.2981 670.5001,-197.2981 677.5001,-197.298\" stroke=\"#000000\"/>\n</g>\n<!-- 12 -->\n<g class=\"node\" id=\"node13\">\n<title>12</title>\n<path d=\"M996.5,-187C996.5,-187 823.5,-187 823.5,-187 817.5,-187 811.5,-181 811.5,-175 811.5,-175 811.5,-116 811.5,-116 811.5,-110 817.5,-104 823.5,-104 823.5,-104 996.5,-104 996.5,-104 1002.5,-104 1008.5,-110 1008.5,-116 1008.5,-116 1008.5,-175 1008.5,-175 1008.5,-181 1002.5,-187 996.5,-187\" fill=\"#f6d1b7\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-171.8\">NumWordsRemoved &lt;= 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-156.8\">gini = 0.475</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-141.8\">samples = 1020</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-126.8\">value = [623, 397]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-111.8\">class = 0</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g class=\"edge\" id=\"edge12\">\n<title>8-&gt;12</title>\n<path d=\"M756.5413,-222.8796C776.5724,-212.7791 798.1064,-201.9209 818.5232,-191.626\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"820.152,-194.7245 827.5053,-187.0969 817.0003,-188.4742 820.152,-194.7245\" stroke=\"#000000\"/>\n</g>\n<!-- 10 -->\n<g class=\"node\" id=\"node11\">\n<title>10</title>\n<path d=\"M672,-68C672,-68 572,-68 572,-68 566,-68 560,-62 560,-56 560,-56 560,-12 560,-12 560,-6 566,0 572,0 572,0 672,0 672,0 678,0 684,-6 684,-12 684,-12 684,-56 684,-56 684,-62 678,-68 672,-68\" fill=\"#eeae80\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-52.8\">gini = 0.387</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-37.8\">samples = 373</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-22.8\">value = [275, 98]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"622\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g class=\"edge\" id=\"edge10\">\n<title>9-&gt;10</title>\n<path d=\"M654.6371,-103.9815C650.6081,-95.3423 646.3511,-86.2144 642.2897,-77.5059\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"645.3782,-75.8472 637.9795,-68.2637 639.0341,-78.8059 645.3782,-75.8472\" stroke=\"#000000\"/>\n</g>\n<!-- 11 -->\n<g class=\"node\" id=\"node12\">\n<title>11</title>\n<path d=\"M814,-68C814,-68 714,-68 714,-68 708,-68 702,-62 702,-56 702,-56 702,-12 702,-12 702,-6 708,0 714,0 714,0 814,0 814,0 820,0 826,-6 826,-12 826,-12 826,-56 826,-56 826,-62 820,-68 814,-68\" fill=\"#eb9c63\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-52.8\">gini = 0.289</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-37.8\">samples = 411</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-22.8\">value = [339, 72]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"764\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g class=\"edge\" id=\"edge11\">\n<title>9-&gt;11</title>\n<path d=\"M707.5127,-103.9815C714.857,-94.8828 722.6388,-85.242 730.0019,-76.1199\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"732.7857,-78.2434 736.3432,-68.2637 727.3388,-73.8467 732.7857,-78.2434\" stroke=\"#000000\"/>\n</g>\n<!-- 13 -->\n<g class=\"node\" id=\"node14\">\n<title>13</title>\n<path d=\"M964,-68C964,-68 856,-68 856,-68 850,-68 844,-62 844,-56 844,-56 844,-12 844,-12 844,-6 850,0 856,0 856,0 964,0 964,0 970,0 976,-6 976,-12 976,-12 976,-56 976,-56 976,-62 970,-68 964,-68\" fill=\"#fefbf8\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-52.8\">gini = 0.5</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-37.8\">samples = 466</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-22.8\">value = [237, 229]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"910\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g class=\"edge\" id=\"edge13\">\n<title>12-&gt;13</title>\n<path d=\"M910,-103.9815C910,-95.618 910,-86.7965 910,-78.3409\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"913.5001,-78.2636 910,-68.2637 906.5001,-78.2637 913.5001,-78.2636\" stroke=\"#000000\"/>\n</g>\n<!-- 14 -->\n<g class=\"node\" id=\"node15\">\n<title>14</title>\n<path d=\"M1114,-68C1114,-68 1006,-68 1006,-68 1000,-68 994,-62 994,-56 994,-56 994,-12 994,-12 994,-6 1000,0 1006,0 1006,0 1114,0 1114,0 1120,0 1126,-6 1126,-12 1126,-12 1126,-56 1126,-56 1126,-62 1120,-68 1114,-68\" fill=\"#f0b88f\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-52.8\">gini = 0.423</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-37.8\">samples = 554</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-22.8\">value = [386, 168]</text>\n<text fill=\"#000000\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"1060\" y=\"-7.8\">class = 0</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g class=\"edge\" id=\"edge14\">\n<title>12-&gt;14</title>\n<path d=\"M965.8545,-103.9815C978.8368,-94.3313 992.6394,-84.0714 1005.5597,-74.4673\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"1007.9678,-77.0384 1013.9054,-68.2637 1003.7917,-71.4204 1007.9678,-77.0384\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1gsRzdIku_j"
      },
      "source": [
        "### Exercise \n",
        "\n",
        "Based on the tree, answer the following questions:\n",
        "1. How many nodes are in the tree? You can count on the image, or use the method `tree_.node_count` on your model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMHU6LP6ku_j",
        "outputId": "e160ae57-9c2e-4b2b-9828-ec9d7e4fb050",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "cart_model.tree_.node_count\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AD484Raznde4"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "\n",
        "There are 15 nodes in the model.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2a9GcIkku_l"
      },
      "source": [
        "2. Which feature variable is split at the root node?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmVJXKg1ku_l"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "\n",
        "The feature variable split at the root node is `LoggedIn`.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9H51saIku_l"
      },
      "source": [
        "3. Apply the `feature_importances` method on your model, which of the feature variables are important? Note, these values returned by `feature_importances` are also known as the Gini measure of the variable. The variables with the larger importance or Gini measures are the ones that we split on at the top of the tree and are considered more important. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXIuMLv1ku_l",
        "outputId": "398f04b0-844f-4bcb-ac9e-100088310d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Write your code here.\n",
        "\n",
        "# -------------------\n",
        "\n",
        "pd.Series(cart_model.feature_importances_, index=X_train.columns)\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Minor              0.007789\n",
              "LoggedIn           0.634670\n",
              "HTTP               0.000000\n",
              "NumWordsAdded      0.276306\n",
              "NumWordsRemoved    0.081235\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53TrWHAonIoV"
      },
      "source": [
        "___\n",
        "__Question 3 Answer__:\n",
        "\n",
        "The most important features are `LogginIn` (0.634670) and `NumWordsAdded` (0.276306)\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UR8Pyncbku_n"
      },
      "source": [
        "4. Assess the accuracy of your model on the testing set. What % of predictions are correct?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqYi7JADku_n",
        "outputId": "bc9f136a-308c-4eec-929d-76e401163d7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "cart_model.fit(X_train, y_train)\n",
        "mdlAcc = np.mean((cart_model.predict(X_test) == y_test))\n",
        "print('The accuracy of this model on the testing data is {:.3f}'.format(round(mdlAcc,3)))\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy of this model on the testing data is 0.717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XXAShRPPn_JW"
      },
      "source": [
        "___\n",
        "__Question 4 Answer__:\n",
        "\n",
        "The accuracy of this model on the testing data is 0.717\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rc6zva3pku_o"
      },
      "source": [
        "5. Constrain the `max_depth` to 10. What is the new accuracy of the model on the training and testing set? Do you think this model has overfit the data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsugiUCiku_o",
        "outputId": "eeb5fe9f-d681-4d6b-cf4a-94fe40d51660",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Write your code here.\n",
        "\n",
        "# -------------------\n",
        "\n",
        "cart_model = DecisionTreeClassifier(random_state=0,max_depth=10)\n",
        "cart_model.fit(X_train, y_train)\n",
        "mdlAccTrain = np.mean((cart_model.predict(X_train) == y_train))\n",
        "mdlAccTest = np.mean((cart_model.predict(X_test) == y_test))\n",
        "\n",
        "print('The accuracy on the: \\n\\t training data is {}'.format(round(mdlAccTrain,3)))\n",
        "print('\\t testing data is {}'.format(round(mdlAccTest,3)))\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy on the: \n",
            "\t training data is 0.773\n",
            "\t testing data is 0.721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLKXsUUzoKnc"
      },
      "source": [
        "___\n",
        "__Question 5 Answer__:\n",
        "\n",
        "'The accuracy of this model on the training data is 0.773, and on the testing data is 0.721. Since the accuracy on the testing data is fairly lower than the training data, we likely overfit the data as the model is not performing well to un-seen data (testing set).\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iaD_4Kn9tch4"
      },
      "source": [
        "Throughout this lab we will fit and \"score\" models several time, so to be efficient (and to follow good coding practice!) we should make a function that fits and scores a model. For future labs and projects you should try to introduce functions where possible. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PccQnTFytdEA",
        "outputId": "642925e0-9b7a-4b21-cee3-86e3ff8c54f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "def fit_and_score_model(mdl, X_train, X_test, y_train, y_test, random_state=0):\n",
        "    \"\"\"\n",
        "    This function will fit and score the input mdl to the X_train and y_train \n",
        "    data, and score the mdl on y_train and y_test. To ensure results are \n",
        "    reproducible we can also set a random state.\n",
        "    \"\"\"\n",
        "  \n",
        "    # Fit an arbitrary model\n",
        "    mdl.fit(X_train, y_train)\n",
        "    \n",
        "    # Calculate the score of the model on training and testing data\n",
        "    train_score = mdl.score(X_train, y_train)\n",
        "    test_score = mdl.score(X_test, y_test)\n",
        "  \n",
        "    # Print scores to terminal\n",
        "    print('the accuracy on the: \\n\\t training data is {}'.format(round(train_score,3)))\n",
        "    print('\\t testing data is {}'.format(round(test_score, 3)))\n",
        "    \n",
        "    return train_score, test_score\n",
        "  \n",
        "# As an example, you can now call the function fit_and_score_model\n",
        "cart_model = DecisionTreeClassifier(random_state=0,max_depth=10)\n",
        "train_score, test_score = fit_and_score_model(cart_model, X_train, X_test, y_train, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.773\n",
            "\t testing data is 0.721\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i75YD2GOku_p"
      },
      "source": [
        "## Random Forest Model\n",
        "\n",
        "As was dicussed in the background section, individual CART trees can tend to overfit the data. To reduce this effect, and improve subsequent model performance, we can combine the results of many decision trees in a random forest.\n",
        "\n",
        "Use the [`RandomForestClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) function from `sklearn.ensemble` to create a random forest model. This function combines classification trees by default (as required) and creates a bootstrapped sample of the full dataset.\n",
        "\n",
        "Set the size of each bootstrapped sample to *0.2*, which corresponds to one fifth the size of the training data by using the `max_samples` parameter. We also set the `bootstrap` parameter to *True*. Note: We didn't have to make the bootstrapped sample size equal to one fifth of the training dataset. This is a parameter that can be tuned, but we will not focus on that for this lab. (It is possible to have the bootstrapped size = full training data set size as well, since our sampling with replacement will still create different datasets used to create each tree).\n",
        "\n",
        "Include 50 individual CART trees in your random forest model using the `n_estimators` parameter. Set the `random_state` attribute to 0 which will allow us to all produce the same results.\n",
        "\n",
        "Experiment with `max_depth` parameter of `RandomForestClassifier` $\\in$ {2, 3, 4, 5, 6, 7} and measure the accuracy on the testing set. \n",
        "\n",
        "Note, we do not need to explicitly specify the proportion of the features we will use for each CART tree in the random forest, because the default setting for `RandomForestClassifier` is $\\sqrt{n\\_features}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ3bimhoku_p",
        "outputId": "3aed3ee8-6679-4cf9-9038-bd863c2d60b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "# from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Write your code here. \n",
        "\n",
        "# -------------------\n",
        "\n",
        "depths = [2, 3, 4, 5, 6, 7]\n",
        "accuracy = pd.Series(index=depths, dtype=float)\n",
        "\n",
        "for max_depth in depths:\n",
        "\n",
        "    # Initialize the model\n",
        "    rf_baseline_model = RandomForestClassifier(\n",
        "        random_state = 0, \n",
        "        max_depth = max_depth,\n",
        "        n_estimators = 50, max_samples = 0.2,\n",
        "        bootstrap = True\n",
        "    )\n",
        "    \n",
        "    # Fit and train model\n",
        "    print('For {} max_depth '.format(max_depth), end='')\n",
        "    train_score, test_score = fit_and_score_model(rf_baseline_model, X_train, X_test, y_train, y_test)\n",
        "    \n",
        "    # Save model performance to dataframe\n",
        "    accuracy.loc[max_depth] = test_score\n",
        "    \n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "For 2 max_depth the accuracy on the: \n",
            "\t training data is 0.712\n",
            "\t testing data is 0.716\n",
            "For 3 max_depth the accuracy on the: \n",
            "\t training data is 0.738\n",
            "\t testing data is 0.724\n",
            "For 4 max_depth the accuracy on the: \n",
            "\t training data is 0.74\n",
            "\t testing data is 0.724\n",
            "For 5 max_depth the accuracy on the: \n",
            "\t training data is 0.752\n",
            "\t testing data is 0.731\n",
            "For 6 max_depth the accuracy on the: \n",
            "\t training data is 0.753\n",
            "\t testing data is 0.73\n",
            "For 7 max_depth the accuracy on the: \n",
            "\t training data is 0.755\n",
            "\t testing data is 0.73\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJaBGSYYku_q"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Based on your random forest model, answer the following questions:\n",
        "1. What was the `max_depth` in your best performing random forest?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BTIlhZ71T6e",
        "outputId": "f6420254-eff8-4ac5-e5fe-b99ec42a99d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Write your code here.\n",
        "# -------------------\n",
        "\n",
        "print('\\nBest model has a max_depth of {}'.format(accuracy.idxmax()))\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Best model has a max_depth of 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QO2arweuxQad"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "The random forest model with a `max_depth` of 5 performed the best on the testing set.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0wmufaLku_r"
      },
      "source": [
        "2. What is the accuracy/score of your best performing random forest?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c34TGZCAku_r",
        "outputId": "f04ee0e2-e787-4c5b-f1b0-525ebff5d1f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Write your code here.\n",
        "# -------------------\n",
        "\n",
        "print('\\nBest model has a score of {:.3f}'.format(accuracy.max()))\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Best model has a score of 0.731\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6vNZ6XNl0b6M"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "The accuracy of the best performing random forest model was 0.737.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmClYcIbku_s"
      },
      "source": [
        "3. Is this a fair way to choose model parameters? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fitc5H7txA7w"
      },
      "source": [
        "___\n",
        "__Question 3 Answer__:\n",
        "\n",
        "No this is not a fair way because parameters were arbitrarily chosen. We need cross validation to find a better selection.\n",
        "___\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0S8skHNku_t"
      },
      "source": [
        "4. Does increasing the `max_depth` increase or decrease overfitting?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVXQwo_SxGor"
      },
      "source": [
        "___\n",
        "__Question 4 Answer__:\n",
        "\n",
        "Increaing the `max_depth` would increase overfitting. This is because the model would become more detailed on the training data and learn nuances in just the training data's patterns. This wouldn't generalize well to un-seen data. \n",
        "\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OMesF84ku_u"
      },
      "source": [
        "5. Does your best random forest model out perform your CART model?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64Np5Mv_xH-l"
      },
      "source": [
        "___\n",
        "__Question 5 Answer__:\n",
        "\n",
        "Yes, our best random forest model achieved an accuracy of 0.737 compared to 0.721 of the best CART model.\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNSEBC4olk1T"
      },
      "source": [
        "# Cross-validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qt-nQmbbrH03"
      },
      "source": [
        "Now that we can code the CART (`DecisionTreeClassifier`) and random forests (`RandomForestClassifier`) it's time to learn about how to adjust parameters to improve model performance. In this section, we'll focus exclusively on the RF, but the methods generalize to other models (e.g., linear regression, CART, deep learning). In the Random Forest section we chose an appropriate value for the `max_dept`h parameter by evaluating the model on the test data (i.e., `X_test` and `y_test`), however, this is cheating because we are using the test set to make modeling decisions. In the real world we should deploy a model that generalizes well to unseen data, and if we use the test set to help tune our model, then the model has \"seen\" the test data so we can no longer offer guarantees about how well it will generalize to unseen data. \n",
        "\n",
        "Using cross-validation, we can choose parameters that generalize to unseen data and help limit over fitting. Cross-validation is a multi-round process. In each round, the the full training set is split into two subsets (1) a subset that the model is trained on, and (2) a subset that the model is evaluated on. After the rounds are complete, an aggregate measure of plan performance (e.g., average score) will be an estimate of the models performance. \n",
        "\n",
        "Now, lets use cross-validation to choose the`max_depth` parameter in our RF model. We will use `cross_validate` from `sklearn` to make the appropriate data splits, and we'll take the model with the highest average score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAm6DP_MlkT9",
        "outputId": "dbc33bd5-1e73-4ae6-be3f-1636df024d81",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# from sklearn.model_selection import cross_validate\n",
        "\n",
        "# Initialize cross validation score DataFrame\n",
        "depth_lb = 1\n",
        "depth_ub = 21\n",
        "cv_scores = pd.Series(index=np.arange(depth_lb, depth_ub), dtype=float)\n",
        "\n",
        "for max_depth in range(depth_lb, depth_ub):\n",
        "  \n",
        "  # Initialize the model\n",
        "  rf_cv1_model = RandomForestClassifier(random_state = 0, max_depth = max_depth,\n",
        "                          n_estimators = 50, max_features = 0.2)\n",
        "\n",
        "  # Run cross validation to get measure of out-of-sample error\n",
        "  example_cv_results = cross_validate(rf_cv1_model, X_train, y_train, cv=5)\n",
        "  \n",
        "  # Record the average out-of-sample error\n",
        "  cv_scores.loc[max_depth] = example_cv_results['test_score'].mean()\n",
        "\n",
        "print(\"Completed\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Completed\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCzSNgRMf7in",
        "outputId": "ffaa5de2-e161-4ea8-c4b8-a9a26ddc33f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "example_cv_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': array([0.10262108, 0.16072917, 0.1082983 , 0.10264659, 0.10189033]),\n",
              " 'score_time': array([0.01004577, 0.01017451, 0.01011944, 0.01070571, 0.01005435]),\n",
              " 'test_score': array([0.72140221, 0.7245841 , 0.73937153, 0.73012939, 0.70794824])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnC_XPJ-gloE",
        "outputId": "bd5cf14a-94ac-4662-868d-ea86d5ad7090",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "cv_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1     0.716559\n",
              "2     0.719147\n",
              "3     0.725789\n",
              "4     0.736880\n",
              "5     0.744274\n",
              "6     0.745753\n",
              "7     0.743537\n",
              "8     0.743168\n",
              "9     0.741692\n",
              "10    0.740582\n",
              "11    0.737624\n",
              "12    0.735406\n",
              "13    0.734299\n",
              "14    0.731710\n",
              "15    0.732450\n",
              "16    0.730602\n",
              "17    0.732450\n",
              "18    0.732081\n",
              "19    0.732081\n",
              "20    0.732450\n",
              "21    0.732820\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIbAvj35qCQa"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Based on this result, answer the following questions:\n",
        "\n",
        "1. Plot the `cv_scores` values. Which `max_depth` would you choose for this model? How does it compare to the `max_depth` you would have picked without cross validation (when we \"cheated\")? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRh8yy73QV7x",
        "outputId": "a03c194b-d375-4166-c1f7-ea4ee9d6cfee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        }
      },
      "source": [
        "# Write your code here.\n",
        "\n",
        "# -------------------\n",
        "sns.scatterplot(x=cv_scores.index, y=cv_scores.values)\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "cv_scores.idxmax()\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFnpnWwnRdVW"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "The max_depth in this model is 6. It is different than the max_depth of 5 we chose before. \n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di6LdQytap6F"
      },
      "source": [
        "2. Based on the cross validations, what value of the `max_depth` parameter would you use to train a RF on this data set? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uq-ROXMs_4cO"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "We would choose a `max_depth` of 6, since cross validation has shown that this is the best value for this parameter.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RmelC9af_57D"
      },
      "source": [
        "3. Write code to perform your own manual cross validation. Do not use functions from `sklearn` other than `RandomForestClassifier`. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWXk4Wg0_78_",
        "outputId": "e47f43a7-c486-4b97-8d3b-ada563fe0659",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here. \n",
        "\n",
        "# -------------------\n",
        "\n",
        "\n",
        "depths = list(range(1, 22))\n",
        "cv_scores = pd.Series(index=depths)\n",
        "\n",
        "cv = 5\n",
        "training_set_size = len(y_train)\n",
        "random_indices = np.random.permutation(training_set_size) # \n",
        "fractional_splits = np.concatenate(([0], np.repeat(1/cv, cv).cumsum())) \n",
        "integer_splits = np.array(np.floor(fractional_splits * training_set_size),dtype=int)\n",
        "\n",
        "\n",
        "for max_depth in depths:\n",
        "  all_val_scores = pd.Series(index=range(cv))\n",
        "  for f in range(cv):\n",
        "    # Get indicies of training and validation partitions\n",
        "    train_partition = np.delete(random_indices, range(*integer_splits[f:f+2]))\n",
        "    val_partition = random_indices[range(*integer_splits[f:f+2])]\n",
        "\n",
        "    # Initialize model\n",
        "    rf_cv3_model = RandomForestClassifier(\n",
        "        random_state = 0, \n",
        "        max_depth = max_depth,\n",
        "        n_estimators = 50, \n",
        "        max_features = 0.2\n",
        "    )\n",
        "\n",
        "    # Fit and score model\n",
        "    _, val_score = fit_and_score_model(\n",
        "        rf_cv3_model, \n",
        "        X_train.iloc[train_partition],\n",
        "        X_train.iloc[val_partition],\n",
        "        y_train.iloc[train_partition],\n",
        "        y_train.iloc[val_partition]\n",
        "    )\n",
        "    all_val_scores.loc[f] = val_score\n",
        "    \n",
        "  cv_scores.loc[max_depth] = all_val_scores.mean()\n",
        "\n",
        "sns.scatterplot(x=cv_scores.index, y=cv_scores.values)\n",
        "plt.xlabel('Max Depth')\n",
        "plt.ylabel('Score')\n",
        "\n",
        "cv_scores.idxmax()\n",
        "# Max depth of 5 was chosen both times.\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.716\n",
            "\t testing data is 0.715\n",
            "the accuracy on the: \n",
            "\t training data is 0.708\n",
            "\t testing data is 0.75\n",
            "the accuracy on the: \n",
            "\t training data is 0.719\n",
            "\t testing data is 0.706\n",
            "the accuracy on the: \n",
            "\t training data is 0.722\n",
            "\t testing data is 0.704\n",
            "the accuracy on the: \n",
            "\t training data is 0.721\n",
            "\t testing data is 0.707\n",
            "the accuracy on the: \n",
            "\t training data is 0.722\n",
            "\t testing data is 0.717\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.712\n",
            "\t testing data is 0.754\n",
            "the accuracy on the: \n",
            "\t training data is 0.723\n",
            "\t testing data is 0.708\n",
            "the accuracy on the: \n",
            "\t training data is 0.724\n",
            "\t testing data is 0.708\n",
            "the accuracy on the: \n",
            "\t training data is 0.721\n",
            "\t testing data is 0.708\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.723\n",
            "\t testing data is 0.717\n",
            "the accuracy on the: \n",
            "\t training data is 0.715\n",
            "\t testing data is 0.76\n",
            "the accuracy on the: \n",
            "\t training data is 0.723\n",
            "\t testing data is 0.702\n",
            "the accuracy on the: \n",
            "\t training data is 0.726\n",
            "\t testing data is 0.708\n",
            "the accuracy on the: \n",
            "\t training data is 0.737\n",
            "\t testing data is 0.742\n",
            "the accuracy on the: \n",
            "\t training data is 0.745\n",
            "\t testing data is 0.734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.735\n",
            "\t testing data is 0.762\n",
            "the accuracy on the: \n",
            "\t training data is 0.747\n",
            "\t testing data is 0.717\n",
            "the accuracy on the: \n",
            "\t training data is 0.742\n",
            "\t testing data is 0.732\n",
            "the accuracy on the: \n",
            "\t training data is 0.753\n",
            "\t testing data is 0.74\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.754\n",
            "\t testing data is 0.743\n",
            "the accuracy on the: \n",
            "\t training data is 0.749\n",
            "\t testing data is 0.763\n",
            "the accuracy on the: \n",
            "\t training data is 0.759\n",
            "\t testing data is 0.73\n",
            "the accuracy on the: \n",
            "\t training data is 0.75\n",
            "\t testing data is 0.747\n",
            "the accuracy on the: \n",
            "\t training data is 0.756\n",
            "\t testing data is 0.738\n",
            "the accuracy on the: \n",
            "\t training data is 0.761\n",
            "\t testing data is 0.734\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.753\n",
            "\t testing data is 0.767\n",
            "the accuracy on the: \n",
            "\t training data is 0.762\n",
            "\t testing data is 0.732\n",
            "the accuracy on the: \n",
            "\t training data is 0.758\n",
            "\t testing data is 0.758\n",
            "the accuracy on the: \n",
            "\t training data is 0.763\n",
            "\t testing data is 0.738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.765\n",
            "\t testing data is 0.741\n",
            "the accuracy on the: \n",
            "\t training data is 0.757\n",
            "\t testing data is 0.767\n",
            "the accuracy on the: \n",
            "\t training data is 0.766\n",
            "\t testing data is 0.73\n",
            "the accuracy on the: \n",
            "\t training data is 0.763\n",
            "\t testing data is 0.747\n",
            "the accuracy on the: \n",
            "\t training data is 0.769\n",
            "\t testing data is 0.732\n",
            "the accuracy on the: \n",
            "\t training data is 0.767\n",
            "\t testing data is 0.738\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.761\n",
            "\t testing data is 0.771\n",
            "the accuracy on the: \n",
            "\t training data is 0.774\n",
            "\t testing data is 0.736\n",
            "the accuracy on the: \n",
            "\t training data is 0.77\n",
            "\t testing data is 0.741\n",
            "the accuracy on the: \n",
            "\t training data is 0.774\n",
            "\t testing data is 0.731\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.775\n",
            "\t testing data is 0.738\n",
            "the accuracy on the: \n",
            "\t training data is 0.766\n",
            "\t testing data is 0.76\n",
            "the accuracy on the: \n",
            "\t training data is 0.778\n",
            "\t testing data is 0.736\n",
            "the accuracy on the: \n",
            "\t training data is 0.775\n",
            "\t testing data is 0.752\n",
            "the accuracy on the: \n",
            "\t training data is 0.781\n",
            "\t testing data is 0.723\n",
            "the accuracy on the: \n",
            "\t training data is 0.779\n",
            "\t testing data is 0.732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.775\n",
            "\t testing data is 0.76\n",
            "the accuracy on the: \n",
            "\t training data is 0.784\n",
            "\t testing data is 0.73\n",
            "the accuracy on the: \n",
            "\t training data is 0.778\n",
            "\t testing data is 0.754\n",
            "the accuracy on the: \n",
            "\t training data is 0.787\n",
            "\t testing data is 0.727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.782\n",
            "\t testing data is 0.732\n",
            "the accuracy on the: \n",
            "\t training data is 0.781\n",
            "\t testing data is 0.756\n",
            "the accuracy on the: \n",
            "\t training data is 0.788\n",
            "\t testing data is 0.726\n",
            "the accuracy on the: \n",
            "\t training data is 0.78\n",
            "\t testing data is 0.747\n",
            "the accuracy on the: \n",
            "\t training data is 0.791\n",
            "\t testing data is 0.727\n",
            "the accuracy on the: \n",
            "\t training data is 0.785\n",
            "\t testing data is 0.725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.782\n",
            "\t testing data is 0.756\n",
            "the accuracy on the: \n",
            "\t training data is 0.793\n",
            "\t testing data is 0.723\n",
            "the accuracy on the: \n",
            "\t training data is 0.782\n",
            "\t testing data is 0.747\n",
            "the accuracy on the: \n",
            "\t training data is 0.793\n",
            "\t testing data is 0.727\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.789\n",
            "\t testing data is 0.728\n",
            "the accuracy on the: \n",
            "\t training data is 0.785\n",
            "\t testing data is 0.752\n",
            "the accuracy on the: \n",
            "\t training data is 0.794\n",
            "\t testing data is 0.713\n",
            "the accuracy on the: \n",
            "\t training data is 0.783\n",
            "\t testing data is 0.756\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.721\n",
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.787\n",
            "\t testing data is 0.743\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.708\n",
            "the accuracy on the: \n",
            "\t training data is 0.785\n",
            "\t testing data is 0.756\n",
            "the accuracy on the: \n",
            "\t training data is 0.796\n",
            "\t testing data is 0.725\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.728\n",
            "the accuracy on the: \n",
            "\t training data is 0.787\n",
            "\t testing data is 0.745\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.713\n",
            "the accuracy on the: \n",
            "\t training data is 0.786\n",
            "\t testing data is 0.754\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n",
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.787\n",
            "\t testing data is 0.741\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.713\n",
            "the accuracy on the: \n",
            "\t training data is 0.785\n",
            "\t testing data is 0.75\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.726\n",
            "the accuracy on the: \n",
            "\t training data is 0.788\n",
            "\t testing data is 0.745\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.715\n",
            "the accuracy on the: \n",
            "\t training data is 0.786\n",
            "\t testing data is 0.754\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n",
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.726\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.788\n",
            "\t testing data is 0.743\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.715\n",
            "the accuracy on the: \n",
            "\t training data is 0.786\n",
            "\t testing data is 0.754\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.73\n",
            "the accuracy on the: \n",
            "\t training data is 0.787\n",
            "\t testing data is 0.741\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.715\n",
            "the accuracy on the: \n",
            "\t training data is 0.786\n",
            "\t testing data is 0.752\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n",
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.728\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.788\n",
            "\t testing data is 0.745\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.715\n",
            "the accuracy on the: \n",
            "\t training data is 0.786\n",
            "\t testing data is 0.752\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.792\n",
            "\t testing data is 0.728\n",
            "the accuracy on the: \n",
            "\t training data is 0.788\n",
            "\t testing data is 0.745\n",
            "the accuracy on the: \n",
            "\t training data is 0.795\n",
            "\t testing data is 0.715\n",
            "the accuracy on the: \n",
            "\t training data is 0.786\n",
            "\t testing data is 0.754\n",
            "the accuracy on the: \n",
            "\t training data is 0.797\n",
            "\t testing data is 0.721\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Lp7X_6M_8J-"
      },
      "source": [
        "4. Compare your RF model to a logistic regression with cross validation (i.e. `LogisticRegressionCV` from `sklearn.lineary_model`). What model is more accurate? "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhlYuflch-bR",
        "outputId": "17af010b-d12e-4987-d1f3-89c112211064",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "# Write your code here.  \n",
        "\n",
        "# -------------------\n",
        "\n",
        "logregcv = LogisticRegressionCV(penalty='l2', solver='lbfgs', cv=5)\n",
        "train_score, test_score = fit_and_score_model(logregcv, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# -------------------"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the accuracy on the: \n",
            "\t training data is 0.717\n",
            "\t testing data is 0.717\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVF9b7CE26Hj"
      },
      "source": [
        "___\n",
        "__Question 4 Answer__:\n",
        "\n",
        "Our best random forest model acheived an accuracy of 0.737 compared to 0.717 of the logistic regression model.\n",
        "\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MqoqOzNku_v"
      },
      "source": [
        "# Reflection\n",
        "As this is an _Analytics in Action_ course, we should think about how valuable our models are with respect to real-world applications. Position yourself as an employee of Wikipedia, and answer the following questions\n",
        "\n",
        "1. Are your models useful to your company in detecting page vandalism? Why or why not?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1J9nrGSAku_v"
      },
      "source": [
        "___\n",
        "__Question 1 Answer__:\n",
        "\n",
        "Currently with only ~75% accuracy, our model isn't ready to be employed by Wikipedia staff. \n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9zPf1h8ku_v"
      },
      "source": [
        "2. What other information about the edits (i.e. feature variables not in the dataset) could be useful to detect vandalism?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7cpL4Crfku_v"
      },
      "source": [
        "___\n",
        "__Question 2 Answer__:\n",
        "\n",
        "Location data of the editor could also be useful in detecting vandalism. Perhaps user age as well.\n",
        "___"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3IALNtNku_v"
      },
      "source": [
        "3. The findings in this work centre around the Language Wiki page. Do you think these methods would extend to other pages too?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnhOl4dOku_w"
      },
      "source": [
        "___\n",
        "__Question 3 Answer__:\n",
        "\n",
        "No. Different categories of pages are likely to have different behaviors with regards to vandalism.\n",
        "___"
      ]
    }
  ]
}